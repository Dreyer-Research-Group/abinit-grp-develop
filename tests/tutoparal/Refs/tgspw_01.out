
.Version 8.11.6 of ABINIT 
.(MPI version, prepared for a x86_64_linux_gnu6.3 computer) 

.Copyright (C) 1998-2019 ABINIT group . 
 ABINIT comes with ABSOLUTELY NO WARRANTY.
 It is free software, and you are welcome to redistribute it
 under certain conditions (GNU General Public License,
 see ~abinit/COPYING or http://www.gnu.org/copyleft/gpl.txt).

 ABINIT is a project of the Universite Catholique de Louvain,
 Corning Inc. and other collaborators, see ~abinit/doc/developers/contributors.txt .
 Please read https://docs.abinit.org/theory/acknowledgments for suggested
 acknowledgments of the ABINIT effort.
 For more information, see https://www.abinit.org .

.Starting date : Thu 28 Mar 2019.
- ( at 14h05 )
  
- input  file    -> tgspw_01.in
- output file    -> tgspw_01.out
- root for input  files -> tgspw_01i
- root for output files -> tgspw_01o


--- !Autoparal
#Autoparal section for GS calculations with paral_kgb
info:
    autoparal: 1
    paral_kgb: 1
    max_ncpus: 108
    nspinor: 1
    nsppol: 1
    nkpt: 1
    mband: 648
configurations:
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 9,
            npband: 12,
            bandpp: 54,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 12,
            npband: 9,
            bandpp: 72,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 2,
            npband: 54,
            bandpp: 12,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 18,
            npband: 6,
            bandpp: 108,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 6,
            npband: 18,
            bandpp: 36,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 3,
            npband: 36,
            bandpp: 18,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 1,
            npband: 108,
            bandpp: 6,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.699630778
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 4,
            npband: 27,
            bandpp: 24,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.698695163
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 18,
            npband: 6,
            bandpp: 54,
            }
    - tot_ncpus: 108
      mpi_ncpus: 108
      efficiency:  0.698695163
      vars: {
            npimage: 1,
            npkpt: 1,
            npspinor: 1,
            npfft: 2,
            npband: 54,
            bandpp: 6,
            }
...

 ====================================================================================================
 Searching for all possible proc distributions for this input with #CPUs<=108:

 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 |       npkpt|       npfft|      npband|      bandpp|  #MPI(proc)|    WEIGHT|
 |    1<<    1|    1<<   22|    1<<  108|    1<<  648|    1<<  108|  <=   108|
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 |           1|           9|          12|          54|         108|    75.560|
 |           1|          12|           9|          72|         108|    75.560|
 |           1|           2|          54|          12|         108|    75.560|
 |           1|          18|           6|         108|         108|    75.560|
 |           1|           6|          18|          36|         108|    75.560|
 |           1|           3|          36|          18|         108|    75.560|
 |           1|           1|         108|           6|         108|    75.560|
 |           1|           4|          27|          24|         108|    75.560|
 |           1|          18|           6|          54|         108|    75.459|
 |           1|           2|          54|           6|         108|    75.459|
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 Only the best possible choices for nproc are printed...

 >>> Possible (best) choices for the number of bands (nband) are:
     with: npfft=9
     nband=   648 using    108 CPUs =   108 MPI x  1 threads (npband=   12)
     nband=   636 using    108 CPUs =   108 MPI x  1 threads (npband=   12)
     nband=   660 using    108 CPUs =   108 MPI x  1 threads (npband=   12)
     nband=   649 using     99 CPUs =    99 MPI x  1 threads (npband=   11)
     nband=   638 using     99 CPUs =    99 MPI x  1 threads (npband=   11)
     nband=   640 using     90 CPUs =    90 MPI x  1 threads (npband=   10)
     nband=   650 using     90 CPUs =    90 MPI x  1 threads (npband=   10)
     nband=   639 using     81 CPUs =    81 MPI x  1 threads (npband=    9)
     nband=   657 using     81 CPUs =    81 MPI x  1 threads (npband=    9)
     nband=   664 using     72 CPUs =    72 MPI x  1 threads (npband=    8)
     nband=   632 using     72 CPUs =    72 MPI x  1 threads (npband=    8)
     nband=   656 using     72 CPUs =    72 MPI x  1 threads (npband=    8)
 >>> The present nband value (   648) seems to be the best choice!

 Launch a parallel version of ABINIT with a distribution of processors among the above list,
 and the associated input variables (npkpt, npband, npfft, bandpp, etc.).
 The higher weight should be better.
 ====================================================================================================


